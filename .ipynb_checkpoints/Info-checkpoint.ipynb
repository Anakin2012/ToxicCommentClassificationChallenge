{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed86d0d",
   "metadata": {},
   "source": [
    "Cilj teme Toxic Comments Classification je da se razvije klasifikacioni model koji moze da razvrsta tekstualne komentare prema svojoj uvredljivosti/toksicnosti. U pitanju je viseklasna klasifikacija, a za samu pripremu teksta i izdvajanje atributa moze se iskoristiti bilo koja reprezentacija (n-grami, tf-id, word2vec, glove, byte pair encoding,..). Sam problem se moze svesti na primenu nekog od klasicnijih modela ucenja (SVM, stabla odlucivanja), ali i nekog dubokog modela (FFN,  RNN, transformera). Posto je vas tim dvoclan, ocekivanja bi bila da se uz analizu skupa i pripremu pokriju i dva modela, jedan klasicni i jedan duboki. Takodje, bilo bi dobro da postoji i neka analiza rezultata, mozda nekih tekstualnih atributa (npr. jedan sjajan alat koji razvija Google je https://pair-code.github.io/lit/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e0fcf",
   "metadata": {},
   "source": [
    " Ideja projekta je da se samostalno oprobate u razvoju modela, da prodjete kroz ceo proces i stignete sto dalje mozete. Neke ideje i trikove mozete pozajmiti iz predlozenih ili drugih izvora, ali se tada ocekuje da izvore i navedete u popisu literature. U radu se mozete oslanjati na tehnike koje smo (ili koje cemo) pokriti na vezbama, ali mozete koristiti i neke alate i pristupe koje biste voleli da istrazite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51bad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5e9ec44",
   "metadata": {},
   "source": [
    "-Svaki projekat mora imati svoju README.md datoteku sa opisom projekta, opisom korišćenog skupa podataka, korišćenom literaturom i imenima članova tima.\n",
    "\n",
    "-Sve Jupyter sveske moraju biti propisno imenovane i sa prefiksima 01, 02, itd. koji ukazuju na redosled kojim projekat treba pregledati. Ukoliko projekat koristi Python skriptove, mora postojati finalna Jupyter demo sveska koja približava funkcionalnosti. \n",
    "\n",
    "-Kod mora biti pristojno iskomentarisan, sa uputstvima koja prate tok projekta. \n",
    "\n",
    "-Za skupove podataka podržati osnovnu analizu koja ukazuje na strukturu skupa, (ne)balansiranost podataka, neka zanimljiva svojstva i slično.\n",
    "\n",
    "-Rezultati modela moraju biti jasno istaknuti, na primer, matrice konfuzije, vrednosti relevantnih metrika i slično. Ukoliko se poredi više modela, rezultate poređenja prikazati grafički (npr. grafikonom sa stubićima, …) i izvesti jasne zaključke.\n",
    "\n",
    "-Prilikom evaluacije i izbora modela posebno obratiti pažnju na kreiranje skupova za treniranje, validaciju i testiranje, greške ovog tipa strogo kažnjavamo!\n",
    "\n",
    "-Testna ispisivanja staviti pok komentar kako se ne bi desilo da imamo duge, nepregledne sveske ili koristiti log datoteke. \n",
    "\n",
    "-Istrenirane modele, propratne skejlere, vektorizatore i slično treba sačuvati. Ukoliko su ovi fajlovi veliki, molimo da ispratite smernice za postavljanje velikih fajlova na GitHub ili da dostavite linkove do odgovarajćeg repozitorijuma sa kojeg se modeli mogu preuzeti (GoogleDrive, OneDrive, WeTransfer, ...) \n",
    "\n",
    "-Svaki projekat mora imati listing paketa  koje je potrebno instalirati i smernice za podešavanje okruženja kako bi projekat mogao da se testira.\n",
    "\n",
    "-Prilikom pregledanja projekata koji se rade u timu, biće praćeni pojedinačni doprinosi. Zato treba voditi računa o ravnopravnoj organizaciji posla i komitovima koji ih prate. U slučaju neravnomernih angažovanja, poeni će biti skalirani. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd6b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517ac10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5bf0fc1",
   "metadata": {},
   "source": [
    "Za odbranu projekta potrebno je pripremiti:\n",
    "\n",
    "-kratku prezentaciju \n",
    "\n",
    "-demo aplikacije.  \n",
    "\n",
    "\n",
    "Prezentacija treba da približi problem koji je razmatran, korišćene modele i skupove podataka, tehnologije i literaturu. Prezentacija može sadržati i druge zanimljivosti poput izazova na koje se naišlo, pokušaja koji nisu bili uspešni i slično. Prezentacije mogu biti u pdf ili Jupyter formatu. \n",
    "\n",
    "Za samu prezentaciju je predviđeno najviše 10 minuta, a za pitanja oko 5 minuta.  \n",
    "\n",
    "\n",
    "Tačni datumi odbrana će biti naknadno objavljivani. \n",
    "\n",
    "Svi projekti u školskoj 2020/21. godini moraju biti kompletirani do 1. septembra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80422b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4409c50a",
   "metadata": {},
   "source": [
    " ## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffcb84",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b820f",
   "metadata": {},
   "source": [
    "You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172d372",
   "metadata": {},
   "source": [
    "- toxic\n",
    "- severe_toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity_hate\n",
    "\n",
    "You must create a model which predicts a probability of each type of toxicity for each comment.\n",
    "\n",
    "File descriptions\n",
    "- train.csv - the training set, contains comments with their binary labels\n",
    "- test.csv - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.\n",
    "- sample_submission.csv - a sample submission file in the correct format\n",
    "- test_labels.csv - labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)\n",
    "\n",
    "\n",
    "Usage\n",
    "The dataset under CC0, with the underlying comment text being governed by Wikipedia's CC-SA-3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3a918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa1d91cd",
   "metadata": {},
   "source": [
    "The inspiration for this toxicity classification challenge comes from the idea of using ML to have better online conversations. Unfortunately, many online discussions devolve into acrimonious arguments, or outright harassment. If conversations are so bad that people leave the discussion, then we have clearly failed to have a online discussion, let alone a good one! This was the basis for working with Wikimedia to create a dataset of comments from Wikipedia Talk pages that have been crowd-evaluated for toxicity (rude, disrespectful, or otherwise likely to make people leave the discussion), as well as the type of toxicity that is present in the comment.\n",
    "\n",
    "The goal is that these machine learning models can be used to help online discussion. You can play with some experiments at https://www.perspectiveapi.com/ and find out more about our research at https://conversationai.github.io/. You can find some of our existing models on github, as well as experiments with mitigating unintended bias in models. At the moment, the PerspectiveAPI does not provide any reasons why a comment might be toxic (so called sub-types of toxicity). From this competition we are particularly excited to see if the additional reasons can help Toxicity models, and also if we can then use them to help online conversations in new ways.\n",
    "\n",
    "Personally, I'm also very interested to see if anyone can adapt capsules for text classification, or if an approach based on transformers will win out, or perhaps it will be one of the many impressive combinations of RNNs with attention, or something else entirely? Either way, I'm looking forward to working together to help have better discussions on the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49e246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd24df1f",
   "metadata": {},
   "source": [
    "VEZBE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450c7cb",
   "metadata": {},
   "source": [
    "https://github.com/matf-ml/materijali-sa-vezbi-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249842b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
