{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ce1f7c",
   "metadata": {},
   "source": [
    "## Solution for Multi-Label Problem\n",
    "Methods for solving Multi-label Classification Problems\n",
    "- Problem Transformation\n",
    "- Adapted Algorithm\n",
    "- Ensemble approaches\n",
    "\n",
    "## Problem Transformation\n",
    "It refers to transforming the multi-label problem into single-label problem(s) by using\n",
    "- Binary Relevance: treats each label as a separate single class classification\n",
    "- Classifier Chains:In this, the first classifier is trained just on the input data and then each next classifier is trained on the input space and all the previous classifiers in the chain.\n",
    "- Label Powerset:we transform the problem into a multi-class problem with one multi-class classifier is trained on all unique label combinations found in the training data.\n",
    "\n",
    "    ## Adapted Algorithm\n",
    "adapting the algorithm to directly perform multi-label classification, rather than transforming the problem into different subsets of problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c3bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b56c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69260a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c0d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83fcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ced7854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksuck piss around work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq man let discuss maybe phone?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>hey @ talk exclusive group wp taliban good des...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>bye! look, come think com back! tosser</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001735f961a23fc4</td>\n",
       "      <td>\" sure, lead must briefly summarize armenia hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0002bcb3da6cb337                          cocksuck piss around work      1   \n",
       "1  00054a5e18b50dd4                   bbq man let discuss maybe phone?      0   \n",
       "2  0005c987bdfc9d4b  hey @ talk exclusive group wp taliban good des...      1   \n",
       "3  0007e25b2121310b             bye! look, come think com back! tosser      1   \n",
       "4  001735f961a23fc4  \" sure, lead must briefly summarize armenia hi...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             1        1       0       1              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('csv/train_02_balanced.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954aeb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31503, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c07bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data['comment_text'].values.astype('U')\n",
    "X = data.drop(labels=['id'], axis=1)\n",
    "y = data.drop(labels = ['id', 'comment_text'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.33, random_state=42)\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', tokenizer=word_tokenize, analyzer='word', ngram_range=(1,3), norm='l2', max_features = 10000)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train['comment_text'])\n",
    "X_test_vec = vectorizer.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd8f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa291e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77ed3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_rel_clf = BinaryRelevance(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7edaf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_rel_clf.fit(X_train_vec,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9929aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_prediction = binary_rel_clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "039086c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#br_prediction.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77438f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060023085802232"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,br_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c7f004b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09447543927151468"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test,br_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8cdc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0130df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a718e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model,mlb_estimator,xtrain,ytrain,xtest,ytest):\n",
    "    # Create an Instance\n",
    "    clf = mlb_estimator(model)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    # Predict\n",
    "    clf_predictions = clf.predict(xtest)\n",
    "    # Check For Accuracy\n",
    "    acc = accuracy_score(ytest,clf_predictions)\n",
    "    ham = hamming_loss(ytest,clf_predictions)\n",
    "    result = {\"accuracy:\":acc,\"hamming_score\":ham}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0177c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_chain_model = build_model(MultinomialNB(),ClassifierChain,X_train_vec,y_train,X_test_vec,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d87d2a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.5986918045402078, 'hamming_score': 0.09981403103757856}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_chain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b672cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_labelP_model = build_model(MultinomialNB(),LabelPowerset,X_train_vec,y_train,X_test_vec,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18a40921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.6079261254328588, 'hamming_score': 0.10159356162626651}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_labelP_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a4688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0af3d877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6293766833397461\n",
      "F1 score =  0.7070272485146485\n",
      "Hamming loss =  0.09170193664229832\n"
     ]
    }
   ],
   "source": [
    "lp_classifier = LabelPowerset(LogisticRegression(max_iter=10000))\n",
    "lp_classifier.fit(X_train_vec, y_train)\n",
    "lp_predictions = lp_classifier.predict(X_test_vec)\n",
    "print(\"Accuracy = \",accuracy_score(y_test,lp_predictions))\n",
    "print(\"F1 score = \",metrics.f1_score(y_test,lp_predictions, average=\"micro\"))\n",
    "print(\"Hamming loss = \",hamming_loss(y_test,lp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b2599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
